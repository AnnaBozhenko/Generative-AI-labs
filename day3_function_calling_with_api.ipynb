{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipython-sql in d:\\kaggle\\genai-5-day\\env\\lib\\site-packages (0.5.0)\n",
      "Requirement already satisfied: prettytable in d:\\kaggle\\genai-5-day\\env\\lib\\site-packages (from ipython-sql) (3.12.0)\n",
      "Requirement already satisfied: ipython in d:\\kaggle\\genai-5-day\\env\\lib\\site-packages (from ipython-sql) (8.29.0)\n",
      "Requirement already satisfied: sqlalchemy>=2.0 in d:\\kaggle\\genai-5-day\\env\\lib\\site-packages (from ipython-sql) (2.0.36)\n",
      "Requirement already satisfied: sqlparse in d:\\kaggle\\genai-5-day\\env\\lib\\site-packages (from ipython-sql) (0.5.1)\n",
      "Requirement already satisfied: six in d:\\kaggle\\genai-5-day\\env\\lib\\site-packages (from ipython-sql) (1.16.0)\n",
      "Requirement already satisfied: ipython-genutils in d:\\kaggle\\genai-5-day\\env\\lib\\site-packages (from ipython-sql) (0.2.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in d:\\kaggle\\genai-5-day\\env\\lib\\site-packages (from sqlalchemy>=2.0->ipython-sql) (4.12.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in d:\\kaggle\\genai-5-day\\env\\lib\\site-packages (from sqlalchemy>=2.0->ipython-sql) (3.1.1)\n",
      "Requirement already satisfied: decorator in d:\\kaggle\\genai-5-day\\env\\lib\\site-packages (from ipython->ipython-sql) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in d:\\kaggle\\genai-5-day\\env\\lib\\site-packages (from ipython->ipython-sql) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in d:\\kaggle\\genai-5-day\\env\\lib\\site-packages (from ipython->ipython-sql) (0.1.7)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in d:\\kaggle\\genai-5-day\\env\\lib\\site-packages (from ipython->ipython-sql) (3.0.48)\n",
      "Requirement already satisfied: pygments>=2.4.0 in d:\\kaggle\\genai-5-day\\env\\lib\\site-packages (from ipython->ipython-sql) (2.18.0)\n",
      "Requirement already satisfied: stack-data in d:\\kaggle\\genai-5-day\\env\\lib\\site-packages (from ipython->ipython-sql) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in d:\\kaggle\\genai-5-day\\env\\lib\\site-packages (from ipython->ipython-sql) (5.14.3)\n",
      "Requirement already satisfied: colorama in d:\\kaggle\\genai-5-day\\env\\lib\\site-packages (from ipython->ipython-sql) (0.4.6)\n",
      "Requirement already satisfied: wcwidth in d:\\kaggle\\genai-5-day\\env\\lib\\site-packages (from prettytable->ipython-sql) (0.2.13)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in d:\\kaggle\\genai-5-day\\env\\lib\\site-packages (from jedi>=0.16->ipython->ipython-sql) (0.8.4)\n",
      "Requirement already satisfied: executing>=1.2.0 in d:\\kaggle\\genai-5-day\\env\\lib\\site-packages (from stack-data->ipython->ipython-sql) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in d:\\kaggle\\genai-5-day\\env\\lib\\site-packages (from stack-data->ipython->ipython-sql) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in d:\\kaggle\\genai-5-day\\env\\lib\\site-packages (from stack-data->ipython->ipython-sql) (0.2.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install ipython-sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vertexai\n",
    "from vertexai.generative_models import GenerativeModel, FunctionDeclaration, Tool\n",
    "\n",
    "from dotenv import dotenv_values\n",
    "\n",
    "import sqlite3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql sqlite:///sample.db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * sqlite:///sample.db\n",
      "Done.\n",
      "Done.\n",
      "Done.\n",
      "3 rows affected.\n",
      "3 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "create table if not exists products (\n",
    "    product_id integer primary key autoincrement,\n",
    "    product_name varchar(255) not null,\n",
    "    price decimal(10, 2) not null\n",
    ");\n",
    "\n",
    "create table if not exists staff (\n",
    "    staff_id integer primary key autoincrement,\n",
    "    first_name varchar(255) not null,\n",
    "    last_name varchar(255) not null\n",
    ");\n",
    "\n",
    "create table if not exists orders (\n",
    "    order_id integer primary key autoincrement,\n",
    "    customer_name varchar(255) not null,\n",
    "    staff_id integer not null,\n",
    "    product_id integer not null,\n",
    "    foreign key (staff_id) references staff (staff_id),\n",
    "    foreign key (product_id) references products (product_id)\n",
    ");\n",
    "\n",
    "-- populate\n",
    "\n",
    "insert into products(product_name, price) values\n",
    "  \t('Laptop', 799.99),\n",
    "  \t('Keyboard', 129.99),\n",
    "  \t('Mouse', 29.99);\n",
    "\n",
    "INSERT INTO orders (customer_name, staff_id, product_id) VALUES\n",
    "  \t('David Lee', 1, 1),\n",
    "  \t('Emily Chen', 2, 2),\n",
    "  \t('Frank Brown', 1, 3);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_file = \"sample.db\"\n",
    "\n",
    "db_conn = sqlite3.connect(db_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_tables() -> list[str]:\n",
    "    \"\"\"Retrieve the names of all tables in the database.\"\"\"\n",
    "    cursor = db_conn.cursor()\n",
    "    cursor.execute(\"select * from sqlite_master where type = 'table';\")\n",
    "    table = cursor.fetchall()\n",
    "    return [t[0] for t in table]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['table', 'table', 'table', 'table']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_tables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_table(table_name: str) -> list[tuple[str, str]]:\n",
    "    \"\"\"Look up the table schema. Returns list of column names, where each entry is a tuple of (column, type).\"\"\"\n",
    "    cursor = db_conn.cursor()\n",
    "    cursor.execute(f\"pragma table_info({table_name});\")\n",
    "    schema = cursor.fetchall()\n",
    "    return [(col[1], col[2]) for col in schema]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('product_id', 'INTEGER'),\n",
       " ('product_name', 'varchar(255)'),\n",
       " ('price', 'decimal(10, 2)')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "describe_table(\"products\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_query(sql: str) -> list[list[str]]:\n",
    "    \"\"\"Execute a SELECT statement, returning the results.\"\"\"\n",
    "    cursor = db_conn.cursor()\n",
    "    cursor.execute(sql)\n",
    "    return cursor.fetchall()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 'Laptop', 799.99),\n",
       " (2, 'Keyboard', 129.99),\n",
       " (3, 'Mouse', 29.99),\n",
       " (4, 'Laptop', 799.99),\n",
       " (5, 'Keyboard', 129.99),\n",
       " (6, 'Mouse', 29.99),\n",
       " (7, 'Laptop', 799.99),\n",
       " (8, 'Keyboard', 129.99),\n",
       " (9, 'Mouse', 29.99)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "execute_query(\"select * from products;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dotenv_values(\".env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_tables_func = FunctionDeclaration(\n",
    "    name=\"list_tables\",\n",
    "    description=\"Retrieve the names of all tables in the database.\",\n",
    "    parameters={\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {}\n",
    "        },\n",
    ")\n",
    "\n",
    "describe_table_func = FunctionDeclaration(\n",
    "    name=\"describe_table\",\n",
    "    description=\"Look up the table schema. Returns list of columns, where each entry is a tuple of (column, type).\",\n",
    "    parameters={\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"table_name\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"Name of the table.\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\n",
    "            \"table_name\"\n",
    "        ]\n",
    "    },\n",
    ")\n",
    "\n",
    "execute_query_func = FunctionDeclaration(\n",
    "    name=\"execute_query\",\n",
    "    description=\"Execute a SELECT statement, returning the results.\",\n",
    "    parameters={\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"sql\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"SQL query to the database.\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\n",
    "            \"sql\"\n",
    "        ]\n",
    "    },\n",
    ")\n",
    "\n",
    "import vertexai\n",
    "from vertexai.generative_models import GenerativeModel, FunctionDeclaration, Tool, Content, Part\n",
    "\n",
    "from dotenv import dotenv_values\n",
    "config = dotenv_values(\".env\")\n",
    "\n",
    "list_tables_func = FunctionDeclaration.from_func(list_tables)\n",
    "describe_table_func = FunctionDeclaration.from_func(describe_table)\n",
    "execute_query_func = FunctionDeclaration.from_func(execute_query)\n",
    "\n",
    "db_tool = vertexai.generative_models.Tool(\n",
    "    function_declarations = [list_tables_func, describe_table_func, execute_query_func]\n",
    ")\n",
    "\n",
    "instruction = \"\"\"You are a helpful chatbot that can interact with an SQL database for a computer\n",
    "store. You will take the users questions and turn them into SQL queries using the tools\n",
    "available. Once you have the information you need, you will answer the user's question using\n",
    "the data returned. Use list_tables to see what tables are present, describe_table to understand\n",
    "the schema, and execute_query to issue an SQL SELECT query.\"\"\"\n",
    "\n",
    "vertexai.init(project=config[\"GOOGLE_PROJECT_ID\"],\n",
    "              location=config[\"LOCATION\"])\n",
    "\n",
    "model = GenerativeModel(\"gemini-1.5-flash-001\",\n",
    "                        tools = [db_tool],\n",
    "                        system_instruction = instruction)\n",
    "\n",
    "chat = model.start_chat()\n",
    "# query = \"What is the most expensive product?\" \n",
    "\n",
    "# resp = chat.send_message(content=query,\n",
    "#                          tools=[db_tool])\n",
    "\n",
    "# function_calls = resp.candidates[0].function_calls\n",
    "# function to give out what i need\n",
    "# function_call = function_calls[-1]\n",
    "# print(function_call)\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "# sql_response = execute_query(function_calls[-1].args.get(\"sql\"))\n",
    "# RESPONSE output\n",
    "# [(1, 'Laptop', 799.99),\n",
    "#  (4, 'Laptop', 799.99),\n",
    "#  (2, 'Keyboard', 129.99),\n",
    "#  (5, 'Keyboard', 129.99),\n",
    "#  (3, 'Mouse', 29.99)]\n",
    "\n",
    "# creating non-techie person readable response, generated from gemini, feeding SQL-query, function from provided API\n",
    "# for func_call in function_calls:\n",
    "#     print(func_call.name)\n",
    "#     function_name = func_call.name\n",
    "\n",
    "#     if function_name == \"list_tables\":\n",
    "#         function = list_tables\n",
    "#         sql_response = function()\n",
    "#         tables = \", \".join(sql_response)\n",
    "#         api_response = {\n",
    "#             \"tables\": tables\n",
    "#         }\n",
    "#     elif function_name == \"describe_table\":\n",
    "#         function = describe_table\n",
    "#         sql_response = function(func_call.args.get(\"table_name\"))\n",
    "#         columns_list = \", \".join([item[0] for item in sql_response])\n",
    "#         api_response = {\n",
    "#             \"columns\": columns_list\n",
    "#         }\n",
    "#     elif function_name == \"execute_query\":\n",
    "#         function = execute_query\n",
    "#         sql_response = function(func_call.args.get(\"sql\"))\n",
    "#         products = \", \".join([item[1] for item in sql_response])\n",
    "#         api_response = {\n",
    "#             \"product_list\": products\n",
    "#         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is the most expensive product?\" \n",
    "\n",
    "resp = chat.send_message(content=query,\n",
    "                         tools=[db_tool])\n",
    "function_calls = resp.candidates[0].function_calls\n",
    "func = function_calls[-1] # the last query is a clue to retrieve user's answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "candidates {\n",
       "  content {\n",
       "    role: \"model\"\n",
       "    parts {\n",
       "      function_call {\n",
       "        name: \"list_tables\"\n",
       "        args {\n",
       "        }\n",
       "      }\n",
       "    }\n",
       "    parts {\n",
       "      text: \"\\n\"\n",
       "    }\n",
       "    parts {\n",
       "      function_call {\n",
       "        name: \"describe_table\"\n",
       "        args {\n",
       "          fields {\n",
       "            key: \"table_name\"\n",
       "            value {\n",
       "              string_value: \"products\"\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "    }\n",
       "    parts {\n",
       "      text: \"\\n\"\n",
       "    }\n",
       "    parts {\n",
       "      function_call {\n",
       "        name: \"execute_query\"\n",
       "        args {\n",
       "          fields {\n",
       "            key: \"sql\"\n",
       "            value {\n",
       "              string_value: \"SELECT name FROM products ORDER BY price DESC LIMIT 1\"\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  finish_reason: STOP\n",
       "  safety_ratings {\n",
       "    category: HARM_CATEGORY_HATE_SPEECH\n",
       "    probability: NEGLIGIBLE\n",
       "    probability_score: 0.168945312\n",
       "    severity: HARM_SEVERITY_NEGLIGIBLE\n",
       "    severity_score: 0.117675781\n",
       "  }\n",
       "  safety_ratings {\n",
       "    category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
       "    probability: NEGLIGIBLE\n",
       "    probability_score: 0.255859375\n",
       "    severity: HARM_SEVERITY_NEGLIGIBLE\n",
       "    severity_score: 0.169921875\n",
       "  }\n",
       "  safety_ratings {\n",
       "    category: HARM_CATEGORY_HARASSMENT\n",
       "    probability: NEGLIGIBLE\n",
       "    probability_score: 0.211914062\n",
       "    severity: HARM_SEVERITY_NEGLIGIBLE\n",
       "    severity_score: 0.103515625\n",
       "  }\n",
       "  safety_ratings {\n",
       "    category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
       "    probability: NEGLIGIBLE\n",
       "    probability_score: 0.117675781\n",
       "    severity: HARM_SEVERITY_NEGLIGIBLE\n",
       "    severity_score: 0.0771484375\n",
       "  }\n",
       "  avg_logprobs: -0.051374638522112812\n",
       "}\n",
       "usage_metadata {\n",
       "  prompt_token_count: 196\n",
       "  candidates_token_count: 27\n",
       "  total_token_count: 223\n",
       "}\n",
       "model_version: \"gemini-1.5-flash-001\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "function_calls = resp.candidates[0].function_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(function_calls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "func = function_calls[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('product_id', 'INTEGER'),\n",
       " ('product_name', 'varchar(255)'),\n",
       " ('price', 'decimal(10, 2)')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "describe_table(\"products\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name: \"execute_query\"\n",
       "args {\n",
       "  fields {\n",
       "    key: \"sql\"\n",
       "    value {\n",
       "      string_value: \"SELECT name FROM products ORDER BY price DESC LIMIT 1\"\n",
       "    }\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SELECT product_name FROM products ORDER BY price DESC LIMIT 1'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func.args[\"sql\"].replace(\"name\", \"product_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SELECT name FROM products ORDER BY price DESC LIMIT 1'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func.args[\"sql\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "func_evaluation = \"SELECT product_name FROM products ORDER BY price DESC LIMIT 1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('product_id', 'INTEGER'),\n",
       " ('product_name', 'varchar(255)'),\n",
       " ('price', 'decimal(10, 2)')]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "describe_table(\"product_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Laptop',)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql_response = execute_query(func_evaluation)\n",
    "sql_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_response = {\"text\": \"; \".join([\", \".join(items) for items in sql_response])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Laptop'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name: \"execute_query\"\n",
       "args {\n",
       "  fields {\n",
       "    key: \"sql\"\n",
       "    value {\n",
       "      string_value: \"SELECT name, price FROM products ORDER BY price DESC LIMIT 1\"\n",
       "    }\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgument",
     "evalue": "400 Please ensure that the number of function response parts should be equal to number of function call parts of the function call turn.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_InactiveRpcError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32md:\\Kaggle\\GenAI-5-day\\env\\Lib\\site-packages\\google\\api_core\\grpc_helpers.py:76\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 76\u001b[0m     \u001b[39mreturn\u001b[39;00m callable_(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     77\u001b[0m \u001b[39mexcept\u001b[39;00m grpc\u001b[39m.\u001b[39mRpcError \u001b[39mas\u001b[39;00m exc:\n",
      "File \u001b[1;32md:\\Kaggle\\GenAI-5-day\\env\\Lib\\site-packages\\grpc\\_channel.py:1181\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable.__call__\u001b[1;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[0;32m   1175\u001b[0m (\n\u001b[0;32m   1176\u001b[0m     state,\n\u001b[0;32m   1177\u001b[0m     call,\n\u001b[0;32m   1178\u001b[0m ) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_blocking(\n\u001b[0;32m   1179\u001b[0m     request, timeout, metadata, credentials, wait_for_ready, compression\n\u001b[0;32m   1180\u001b[0m )\n\u001b[1;32m-> 1181\u001b[0m \u001b[39mreturn\u001b[39;00m _end_unary_response_blocking(state, call, \u001b[39mFalse\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m)\n",
      "File \u001b[1;32md:\\Kaggle\\GenAI-5-day\\env\\Lib\\site-packages\\grpc\\_channel.py:1006\u001b[0m, in \u001b[0;36m_end_unary_response_blocking\u001b[1;34m(state, call, with_call, deadline)\u001b[0m\n\u001b[0;32m   1005\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1006\u001b[0m     \u001b[39mraise\u001b[39;00m _InactiveRpcError(state)\n",
      "\u001b[1;31m_InactiveRpcError\u001b[0m: <_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.INVALID_ARGUMENT\n\tdetails = \"Please ensure that the number of function response parts should be equal to number of function call parts of the function call turn.\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer ipv4:216.58.208.202:443 {created_time:\"2024-11-14T08:20:17.3705454+00:00\", grpc_status:3, grpc_message:\"Please ensure that the number of function response parts should be equal to number of function call parts of the function call turn.\"}\"\n>",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mInvalidArgument\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m user_response \u001b[39m=\u001b[39m chat\u001b[39m.\u001b[39;49msend_message(\n\u001b[0;32m      2\u001b[0m     Content(\n\u001b[0;32m      3\u001b[0m             role \u001b[39m=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39muser\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m      4\u001b[0m             parts \u001b[39m=\u001b[39;49m [Part\u001b[39m.\u001b[39;49mfrom_function_response(name \u001b[39m=\u001b[39;49m func\u001b[39m.\u001b[39;49mname, response \u001b[39m=\u001b[39;49m {\u001b[39m\"\u001b[39;49m\u001b[39mcontent\u001b[39;49m\u001b[39m\"\u001b[39;49m: api_response})]\n\u001b[0;32m      5\u001b[0m     )\n\u001b[0;32m      6\u001b[0m )\n",
      "File \u001b[1;32md:\\Kaggle\\GenAI-5-day\\env\\Lib\\site-packages\\vertexai\\generative_models\\_generative_models.py:1257\u001b[0m, in \u001b[0;36mChatSession.send_message\u001b[1;34m(self, content, generation_config, safety_settings, tools, labels, stream)\u001b[0m\n\u001b[0;32m   1249\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_send_message_streaming(\n\u001b[0;32m   1250\u001b[0m         content\u001b[39m=\u001b[39mcontent,\n\u001b[0;32m   1251\u001b[0m         generation_config\u001b[39m=\u001b[39mgeneration_config,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1254\u001b[0m         labels\u001b[39m=\u001b[39mlabels,\n\u001b[0;32m   1255\u001b[0m     )\n\u001b[0;32m   1256\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1257\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_message(\n\u001b[0;32m   1258\u001b[0m         content\u001b[39m=\u001b[39;49mcontent,\n\u001b[0;32m   1259\u001b[0m         generation_config\u001b[39m=\u001b[39;49mgeneration_config,\n\u001b[0;32m   1260\u001b[0m         safety_settings\u001b[39m=\u001b[39;49msafety_settings,\n\u001b[0;32m   1261\u001b[0m         tools\u001b[39m=\u001b[39;49mtools,\n\u001b[0;32m   1262\u001b[0m         labels\u001b[39m=\u001b[39;49mlabels,\n\u001b[0;32m   1263\u001b[0m     )\n",
      "File \u001b[1;32md:\\Kaggle\\GenAI-5-day\\env\\Lib\\site-packages\\vertexai\\generative_models\\_generative_models.py:1386\u001b[0m, in \u001b[0;36mChatSession._send_message\u001b[1;34m(self, content, generation_config, safety_settings, tools, labels)\u001b[0m\n\u001b[0;32m   1384\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m   1385\u001b[0m     request_history \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_history \u001b[39m+\u001b[39m history_delta\n\u001b[1;32m-> 1386\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_model\u001b[39m.\u001b[39;49m_generate_content(\n\u001b[0;32m   1387\u001b[0m         contents\u001b[39m=\u001b[39;49mrequest_history,\n\u001b[0;32m   1388\u001b[0m         generation_config\u001b[39m=\u001b[39;49mgeneration_config,\n\u001b[0;32m   1389\u001b[0m         safety_settings\u001b[39m=\u001b[39;49msafety_settings,\n\u001b[0;32m   1390\u001b[0m         tools\u001b[39m=\u001b[39;49mtools,\n\u001b[0;32m   1391\u001b[0m         labels\u001b[39m=\u001b[39;49mlabels,\n\u001b[0;32m   1392\u001b[0m     )\n\u001b[0;32m   1393\u001b[0m     \u001b[39m# By default we're not adding incomplete interactions to history.\u001b[39;00m\n\u001b[0;32m   1394\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_response_validator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32md:\\Kaggle\\GenAI-5-day\\env\\Lib\\site-packages\\vertexai\\generative_models\\_generative_models.py:779\u001b[0m, in \u001b[0;36m_GenerativeModel._generate_content\u001b[1;34m(self, contents, generation_config, safety_settings, tools, tool_config, labels)\u001b[0m\n\u001b[0;32m    752\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Generates content.\u001b[39;00m\n\u001b[0;32m    753\u001b[0m \n\u001b[0;32m    754\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    769\u001b[0m \u001b[39m    A single GenerationResponse object\u001b[39;00m\n\u001b[0;32m    770\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    771\u001b[0m request \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_request(\n\u001b[0;32m    772\u001b[0m     contents\u001b[39m=\u001b[39mcontents,\n\u001b[0;32m    773\u001b[0m     generation_config\u001b[39m=\u001b[39mgeneration_config,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    777\u001b[0m     labels\u001b[39m=\u001b[39mlabels,\n\u001b[0;32m    778\u001b[0m )\n\u001b[1;32m--> 779\u001b[0m gapic_response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_prediction_client\u001b[39m.\u001b[39;49mgenerate_content(request\u001b[39m=\u001b[39;49mrequest)\n\u001b[0;32m    780\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_parse_response(gapic_response)\n",
      "File \u001b[1;32md:\\Kaggle\\GenAI-5-day\\env\\Lib\\site-packages\\google\\cloud\\aiplatform_v1\\services\\prediction_service\\client.py:2159\u001b[0m, in \u001b[0;36mPredictionServiceClient.generate_content\u001b[1;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[0;32m   2156\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_universe_domain()\n\u001b[0;32m   2158\u001b[0m \u001b[39m# Send the request.\u001b[39;00m\n\u001b[1;32m-> 2159\u001b[0m response \u001b[39m=\u001b[39m rpc(\n\u001b[0;32m   2160\u001b[0m     request,\n\u001b[0;32m   2161\u001b[0m     retry\u001b[39m=\u001b[39;49mretry,\n\u001b[0;32m   2162\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[0;32m   2163\u001b[0m     metadata\u001b[39m=\u001b[39;49mmetadata,\n\u001b[0;32m   2164\u001b[0m )\n\u001b[0;32m   2166\u001b[0m \u001b[39m# Done; return the response.\u001b[39;00m\n\u001b[0;32m   2167\u001b[0m \u001b[39mreturn\u001b[39;00m response\n",
      "File \u001b[1;32md:\\Kaggle\\GenAI-5-day\\env\\Lib\\site-packages\\google\\api_core\\gapic_v1\\method.py:131\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[1;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compression \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    129\u001b[0m     kwargs[\u001b[39m\"\u001b[39m\u001b[39mcompression\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m compression\n\u001b[1;32m--> 131\u001b[0m \u001b[39mreturn\u001b[39;00m wrapped_func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32md:\\Kaggle\\GenAI-5-day\\env\\Lib\\site-packages\\google\\api_core\\grpc_helpers.py:78\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     76\u001b[0m     \u001b[39mreturn\u001b[39;00m callable_(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     77\u001b[0m \u001b[39mexcept\u001b[39;00m grpc\u001b[39m.\u001b[39mRpcError \u001b[39mas\u001b[39;00m exc:\n\u001b[1;32m---> 78\u001b[0m     \u001b[39mraise\u001b[39;00m exceptions\u001b[39m.\u001b[39mfrom_grpc_error(exc) \u001b[39mfrom\u001b[39;00m \u001b[39mexc\u001b[39;00m\n",
      "\u001b[1;31mInvalidArgument\u001b[0m: 400 Please ensure that the number of function response parts should be equal to number of function call parts of the function call turn."
     ]
    }
   ],
   "source": [
    "user_response = chat.send_message(\n",
    "    Content(\n",
    "            role = \"user\",\n",
    "            parts = [Part.from_function_response(name = func.name, response = {\"content\": api_response})]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.api_core import retry\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retry_with_policy(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        retry_policy = retry.Retry(predicate=retry.if_transient_error)\n",
    "        return retry_policy(func)(*args, **kwargs)\n",
    "    return wrapper\n",
    "\n",
    "@retry_with_policy\n",
    "def send_message_with_retry(chat, message, *, tools):\n",
    "    chat.send_message(message, tools=tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = model.start_chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What are top expensive products?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resp = send_message_with_retry(chat, \"What is the cheapest product?\")\n",
    "resp = chat.send_message(content=query,\n",
    "                         tools=[db_tool])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "role: \"model\"\n",
       "parts {\n",
       "  function_call {\n",
       "    name: \"list_tables\"\n",
       "    args {\n",
       "    }\n",
       "  }\n",
       "}\n",
       "parts {\n",
       "  text: \"\\n\"\n",
       "}\n",
       "parts {\n",
       "  function_call {\n",
       "    name: \"describe_table\"\n",
       "    args {\n",
       "      fields {\n",
       "        key: \"table_name\"\n",
       "        value {\n",
       "          string_value: \"products\"\n",
       "        }\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "parts {\n",
       "  text: \"\\n\"\n",
       "}\n",
       "parts {\n",
       "  function_call {\n",
       "    name: \"execute_query\"\n",
       "    args {\n",
       "      fields {\n",
       "        key: \"sql\"\n",
       "        value {\n",
       "          string_value: \"SELECT * FROM products ORDER BY price DESC LIMIT 5\"\n",
       "        }\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp.candidates[0].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function_calls = resp.candidates[0].function_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vertexai.generative_models import Content, Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 'Laptop', 799.99),\n",
       " (4, 'Laptop', 799.99),\n",
       " (2, 'Keyboard', 129.99),\n",
       " (5, 'Keyboard', 129.99),\n",
       " (3, 'Mouse', 29.99)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "execute_query(function_calls[-1].args.get(\"sql\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list_tables\n"
     ]
    },
    {
     "ename": "InvalidArgument",
     "evalue": "400 Please ensure that the number of function response parts should be equal to number of function call parts of the function call turn.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_InactiveRpcError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32md:\\Kaggle\\GenAI-5-day\\env\\Lib\\site-packages\\google\\api_core\\grpc_helpers.py:76\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 76\u001b[0m     \u001b[39mreturn\u001b[39;00m callable_(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     77\u001b[0m \u001b[39mexcept\u001b[39;00m grpc\u001b[39m.\u001b[39mRpcError \u001b[39mas\u001b[39;00m exc:\n",
      "File \u001b[1;32md:\\Kaggle\\GenAI-5-day\\env\\Lib\\site-packages\\grpc\\_channel.py:1181\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable.__call__\u001b[1;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[0;32m   1175\u001b[0m (\n\u001b[0;32m   1176\u001b[0m     state,\n\u001b[0;32m   1177\u001b[0m     call,\n\u001b[0;32m   1178\u001b[0m ) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_blocking(\n\u001b[0;32m   1179\u001b[0m     request, timeout, metadata, credentials, wait_for_ready, compression\n\u001b[0;32m   1180\u001b[0m )\n\u001b[1;32m-> 1181\u001b[0m \u001b[39mreturn\u001b[39;00m _end_unary_response_blocking(state, call, \u001b[39mFalse\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m)\n",
      "File \u001b[1;32md:\\Kaggle\\GenAI-5-day\\env\\Lib\\site-packages\\grpc\\_channel.py:1006\u001b[0m, in \u001b[0;36m_end_unary_response_blocking\u001b[1;34m(state, call, with_call, deadline)\u001b[0m\n\u001b[0;32m   1005\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1006\u001b[0m     \u001b[39mraise\u001b[39;00m _InactiveRpcError(state)\n",
      "\u001b[1;31m_InactiveRpcError\u001b[0m: <_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.INVALID_ARGUMENT\n\tdetails = \"Please ensure that the number of function response parts should be equal to number of function call parts of the function call turn.\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer ipv4:216.58.209.10:443 {grpc_message:\"Please ensure that the number of function response parts should be equal to number of function call parts of the function call turn.\", grpc_status:3, created_time:\"2024-11-14T02:19:51.2903467+00:00\"}\"\n>",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mInvalidArgument\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[47], line 51\u001b[0m\n\u001b[0;32m     35\u001b[0m     api_response \u001b[39m=\u001b[39m {\n\u001b[0;32m     36\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mproduct_list\u001b[39m\u001b[39m\"\u001b[39m: products\n\u001b[0;32m     37\u001b[0m     }\n\u001b[0;32m     39\u001b[0m     \u001b[39m# print(api_response)\u001b[39;00m\n\u001b[0;32m     40\u001b[0m     \u001b[39m# Create a separate Content object for each function call\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[39m# content = Content(parts=[Part.from_function_response(name=func_call.name, response={\"content\": api_response})])\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[39m#     tools=[db_tool],\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[39m# )\u001b[39;00m\n\u001b[1;32m---> 51\u001b[0m response \u001b[39m=\u001b[39m chat\u001b[39m.\u001b[39;49msend_message(\n\u001b[0;32m     52\u001b[0m     Part\u001b[39m.\u001b[39;49mfrom_function_response(name \u001b[39m=\u001b[39;49m function_name, response\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39mcontent\u001b[39;49m\u001b[39m\"\u001b[39;49m: api_response})\n\u001b[0;32m     53\u001b[0m )\n\u001b[0;32m     54\u001b[0m \u001b[39mprint\u001b[39m(response\u001b[39m.\u001b[39mtext)\n",
      "File \u001b[1;32md:\\Kaggle\\GenAI-5-day\\env\\Lib\\site-packages\\vertexai\\generative_models\\_generative_models.py:1257\u001b[0m, in \u001b[0;36mChatSession.send_message\u001b[1;34m(self, content, generation_config, safety_settings, tools, labels, stream)\u001b[0m\n\u001b[0;32m   1249\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_send_message_streaming(\n\u001b[0;32m   1250\u001b[0m         content\u001b[39m=\u001b[39mcontent,\n\u001b[0;32m   1251\u001b[0m         generation_config\u001b[39m=\u001b[39mgeneration_config,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1254\u001b[0m         labels\u001b[39m=\u001b[39mlabels,\n\u001b[0;32m   1255\u001b[0m     )\n\u001b[0;32m   1256\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1257\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_message(\n\u001b[0;32m   1258\u001b[0m         content\u001b[39m=\u001b[39;49mcontent,\n\u001b[0;32m   1259\u001b[0m         generation_config\u001b[39m=\u001b[39;49mgeneration_config,\n\u001b[0;32m   1260\u001b[0m         safety_settings\u001b[39m=\u001b[39;49msafety_settings,\n\u001b[0;32m   1261\u001b[0m         tools\u001b[39m=\u001b[39;49mtools,\n\u001b[0;32m   1262\u001b[0m         labels\u001b[39m=\u001b[39;49mlabels,\n\u001b[0;32m   1263\u001b[0m     )\n",
      "File \u001b[1;32md:\\Kaggle\\GenAI-5-day\\env\\Lib\\site-packages\\vertexai\\generative_models\\_generative_models.py:1386\u001b[0m, in \u001b[0;36mChatSession._send_message\u001b[1;34m(self, content, generation_config, safety_settings, tools, labels)\u001b[0m\n\u001b[0;32m   1384\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m   1385\u001b[0m     request_history \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_history \u001b[39m+\u001b[39m history_delta\n\u001b[1;32m-> 1386\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_model\u001b[39m.\u001b[39;49m_generate_content(\n\u001b[0;32m   1387\u001b[0m         contents\u001b[39m=\u001b[39;49mrequest_history,\n\u001b[0;32m   1388\u001b[0m         generation_config\u001b[39m=\u001b[39;49mgeneration_config,\n\u001b[0;32m   1389\u001b[0m         safety_settings\u001b[39m=\u001b[39;49msafety_settings,\n\u001b[0;32m   1390\u001b[0m         tools\u001b[39m=\u001b[39;49mtools,\n\u001b[0;32m   1391\u001b[0m         labels\u001b[39m=\u001b[39;49mlabels,\n\u001b[0;32m   1392\u001b[0m     )\n\u001b[0;32m   1393\u001b[0m     \u001b[39m# By default we're not adding incomplete interactions to history.\u001b[39;00m\n\u001b[0;32m   1394\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_response_validator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32md:\\Kaggle\\GenAI-5-day\\env\\Lib\\site-packages\\vertexai\\generative_models\\_generative_models.py:779\u001b[0m, in \u001b[0;36m_GenerativeModel._generate_content\u001b[1;34m(self, contents, generation_config, safety_settings, tools, tool_config, labels)\u001b[0m\n\u001b[0;32m    752\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Generates content.\u001b[39;00m\n\u001b[0;32m    753\u001b[0m \n\u001b[0;32m    754\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    769\u001b[0m \u001b[39m    A single GenerationResponse object\u001b[39;00m\n\u001b[0;32m    770\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    771\u001b[0m request \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_request(\n\u001b[0;32m    772\u001b[0m     contents\u001b[39m=\u001b[39mcontents,\n\u001b[0;32m    773\u001b[0m     generation_config\u001b[39m=\u001b[39mgeneration_config,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    777\u001b[0m     labels\u001b[39m=\u001b[39mlabels,\n\u001b[0;32m    778\u001b[0m )\n\u001b[1;32m--> 779\u001b[0m gapic_response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_prediction_client\u001b[39m.\u001b[39;49mgenerate_content(request\u001b[39m=\u001b[39;49mrequest)\n\u001b[0;32m    780\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_parse_response(gapic_response)\n",
      "File \u001b[1;32md:\\Kaggle\\GenAI-5-day\\env\\Lib\\site-packages\\google\\cloud\\aiplatform_v1\\services\\prediction_service\\client.py:2159\u001b[0m, in \u001b[0;36mPredictionServiceClient.generate_content\u001b[1;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[0;32m   2156\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_universe_domain()\n\u001b[0;32m   2158\u001b[0m \u001b[39m# Send the request.\u001b[39;00m\n\u001b[1;32m-> 2159\u001b[0m response \u001b[39m=\u001b[39m rpc(\n\u001b[0;32m   2160\u001b[0m     request,\n\u001b[0;32m   2161\u001b[0m     retry\u001b[39m=\u001b[39;49mretry,\n\u001b[0;32m   2162\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[0;32m   2163\u001b[0m     metadata\u001b[39m=\u001b[39;49mmetadata,\n\u001b[0;32m   2164\u001b[0m )\n\u001b[0;32m   2166\u001b[0m \u001b[39m# Done; return the response.\u001b[39;00m\n\u001b[0;32m   2167\u001b[0m \u001b[39mreturn\u001b[39;00m response\n",
      "File \u001b[1;32md:\\Kaggle\\GenAI-5-day\\env\\Lib\\site-packages\\google\\api_core\\gapic_v1\\method.py:131\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[1;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compression \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    129\u001b[0m     kwargs[\u001b[39m\"\u001b[39m\u001b[39mcompression\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m compression\n\u001b[1;32m--> 131\u001b[0m \u001b[39mreturn\u001b[39;00m wrapped_func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32md:\\Kaggle\\GenAI-5-day\\env\\Lib\\site-packages\\google\\api_core\\grpc_helpers.py:78\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     76\u001b[0m     \u001b[39mreturn\u001b[39;00m callable_(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     77\u001b[0m \u001b[39mexcept\u001b[39;00m grpc\u001b[39m.\u001b[39mRpcError \u001b[39mas\u001b[39;00m exc:\n\u001b[1;32m---> 78\u001b[0m     \u001b[39mraise\u001b[39;00m exceptions\u001b[39m.\u001b[39mfrom_grpc_error(exc) \u001b[39mfrom\u001b[39;00m \u001b[39mexc\u001b[39;00m\n",
      "\u001b[1;31mInvalidArgument\u001b[0m: 400 Please ensure that the number of function response parts should be equal to number of function call parts of the function call turn."
     ]
    }
   ],
   "source": [
    "function_handler = {\n",
    "    \"list_tables\": list_tables,\n",
    "    \"describe_table\": describe_table,\n",
    "    \"execute_query\": execute_query\n",
    "}\n",
    "\n",
    "# function_parameters = {\n",
    "#     \"list_tables\": None,\n",
    "#     \"describe_table\": \"table_name\",\n",
    "#     \"execute_query\": execute_query\n",
    "# }\n",
    "\n",
    "# for func_call in function_calls:\n",
    "#     print(func_call.name)\n",
    "#     function_name = func_call.name\n",
    "\n",
    "#     if function_name == \"list_tables\":\n",
    "#         function = list_tables\n",
    "#         sql_response = function()\n",
    "#         tables = \", \".join(sql_response)\n",
    "#         api_response = {\n",
    "#             \"tables\": tables\n",
    "#         }\n",
    "#     elif function_name == \"describe_table\":\n",
    "#         function = describe_table\n",
    "#         sql_response = function(func_call.args.get(\"table_name\"))\n",
    "#         columns_list = \", \".join([item[0] for item in sql_response])\n",
    "#         api_response = {\n",
    "#             \"columns\": columns_list\n",
    "#         }\n",
    "#     elif function_name == \"execute_query\":\n",
    "#         function = execute_query\n",
    "#         sql_response = function(func_call.args.get(\"sql\"))\n",
    "#         products = \", \".join([item[1] for item in sql_response])\n",
    "#         api_response = {\n",
    "#             \"product_list\": products\n",
    "#         }\n",
    "\n",
    "        # print(api_response)\n",
    "        # Create a separate Content object for each function call\n",
    "    # content = Content(parts=[Part.from_function_response(name=func_call.name, response={\"content\": api_response})])\n",
    "    # Use the generated content and content object in your prompt\n",
    "    # response = model.generate_content(\n",
    "    #     [\n",
    "    #         query,\n",
    "    #         resp.candidates[0].content,\n",
    "    #         content,\n",
    "    #     ],\n",
    "    #     tools=[db_tool],\n",
    "    # )\n",
    "    # response = chat.send_message(\n",
    "    #     Part.from_function_response(name = function_name, response={\"content\": api_response})\n",
    "    # )\n",
    "    # print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 'Laptop', 799.99), (4, 'Laptop', 799.99), (2, 'Keyboard', 129.99)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function_call = function_calls[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name: \"execute_query\"\n",
       "args {\n",
       "  fields {\n",
       "    key: \"sql\"\n",
       "    value {\n",
       "      string_value: \"SELECT * FROM products ORDER BY price DESC LIMIT 3\"\n",
       "    }\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function_call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "role: \"model\"\n",
       "parts {\n",
       "  function_call {\n",
       "    name: \"list_tables\"\n",
       "    args {\n",
       "    }\n",
       "  }\n",
       "}\n",
       "parts {\n",
       "  text: \"\\n\"\n",
       "}\n",
       "parts {\n",
       "  function_call {\n",
       "    name: \"describe_table\"\n",
       "    args {\n",
       "      fields {\n",
       "        key: \"table_name\"\n",
       "        value {\n",
       "          string_value: \"products\"\n",
       "        }\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "parts {\n",
       "  text: \"\\n\"\n",
       "}\n",
       "parts {\n",
       "  function_call {\n",
       "    name: \"execute_query\"\n",
       "    args {\n",
       "      fields {\n",
       "        key: \"sql\"\n",
       "        value {\n",
       "          string_value: \"SELECT * FROM products ORDER BY price DESC LIMIT 3\"\n",
       "        }\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp.candidates[0].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_response = model.generate_content(\n",
    "    [\n",
    "        \"What are three most expensive products?\",\n",
    "        resp.candidates[0].content,\n",
    "        Content(\n",
    "            parts = [\n",
    "                Part.from_function_response(\n",
    "                    name = function_call.name,\n",
    "                    response={\"content\": response},\n",
    "                ),\n",
    "            ],\n",
    "        ),\n",
    "    ],\n",
    "    tools=[db_tool]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = send_message_with_retry(chat, \"and how much is it?\",\n",
    "                               tools = [db_tool])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
